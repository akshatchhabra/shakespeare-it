{"cells":[{"cell_type":"markdown","source":["This code is taken from our first homework in 685, and is modified to solve our task!"],"metadata":{"id":"0oSCWU_Vn195"}},{"cell_type":"code","source":["# Please note that this code just follows the provided video\n","# Mount data from drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Folder name\n","folderName = 'UMass/Spring 2022/COMPSCI685/CS685 Project/Sanity Check'\n","assert folderName is not None, \"[Error] Please enter folder name.\"\n","\n","\n","# Load python files from our folder\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(folderName))\n","\n","%cd /content/drive/My\\ Drive/$folderName/ "],"metadata":{"id":"4n41zecstDwO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652390939556,"user_tz":240,"elapsed":2690,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"}},"outputId":"1c295f13-b7c9-4884-b023-59b85b1fb931"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1s39Gy1mP7wbq26JnrSjY-Rsch9COaNmZ/Spring 2022/COMPSCI685/CS685 Project/Sanity Check\n"]}]},{"cell_type":"markdown","metadata":{"id":"d23zfO_ALKeB"},"source":["# Text classification"]},{"cell_type":"markdown","metadata":{"id":"N25dvF4jvYoy"},"source":["Now we'll move onto fine-tuning  pretrained language models specifically on your dataset. This part of the homework is meant to be an introduction to the HuggingFace library, and it contains code that will potentially be useful for your final projects. Since we're dealing with large models, the first step is to change to a GPU runtime.\n","\n","## Adding a hardware accelerator\n","\n","Please go to the menu and add a GPU as follows:\n","\n","`Edit > Notebook Settings > Hardware accelerator > (GPU)`\n","\n","Run the following cell to confirm that the GPU is detected."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2810,"status":"ok","timestamp":1652390972945,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"},"user_tz":240},"id":"edOh9ooiIW1B","outputId":"5223cc40-c68c-4e04-a47c-c693f487bde0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found device: Tesla T4, n_gpu: 1\n"]}],"source":["import torch\n","\n","# Confirm that the GPU is detected\n","\n","assert torch.cuda.is_available()\n","\n","# Get the GPU device name.\n","device_name = torch.cuda.get_device_name()\n","n_gpu = torch.cuda.device_count()\n","print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n","device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"xrvH7xx9LnMC"},"source":["## Installing Hugging Face's Transformers library\n","We will use Hugging Face's Transformers (https://github.com/huggingface/transformers), an open-source library that provides general-purpose architectures for natural language understanding and generation with a collection of various pretrained models made by the NLP community. This library will allow us to easily use pretrained models like `BERT` and perform experiments on top of them. We can use these models to solve downstream target tasks, such as text classification, question answering, and sequence labeling.\n","\n","Run the following cell to install Hugging Face's Transformers library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25542,"status":"ok","timestamp":1652391005855,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"},"user_tz":240},"id":"gtqS2e5fxpqa","outputId":"5b138869-c97a-464b-916b-f6b67eb062a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 64.3 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0\n","success!\n","helper file downloaded! (helpers.py)\n"]}],"source":["!pip install transformers\n","!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","print('success!')\n","\n","import os\n","import zipfile\n","\n","# Download helper functions file\n","helper_file = drive.CreateFile({'id': '16HW-z9Y1tM3gZ_vFpJAuwUDohz91Aac-'})\n","helper_file.GetContentFile('helpers.py')\n","print('helper file downloaded! (helpers.py)')"]},{"cell_type":"markdown","metadata":{"id":"gKc0xYh-MAbc"},"source":["# Data Prep and Model Specifications"]},{"cell_type":"markdown","source":["## Create train/test/validation splits"],"metadata":{"id":"qqVFC-4Wz5VN"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from helpers import tokenize_and_format, flat_accuracy\n","import pandas as pd\n","\n","def build_data_set(texts, labels):\n","  ### tokenize_and_format() is a helper function provided in helpers.py ###\n","  input_ids, attention_masks = tokenize_and_format(texts)\n","\n","  input_ids = torch.cat(input_ids, dim=0)\n","  attention_masks = torch.cat(attention_masks, dim=0)\n","  labels = torch.tensor(labels)\n","\n","  return [(input_ids[i], attention_masks[i], labels[i]) for i in range(len(texts))]\n","\n","def get_test_set_text(filename):\n","  classifier_df = pd.read_csv(filename)\n","  classifier_df[\"text\"] = classifier_df['Generated Text']\n","\n","  classifier_df[\"label\"] = 1\n","  classifier_df = classifier_df[[\"text\", \"label\"]]\n","  classifier_df.head()\n","\n","  texts = classifier_df.text.values\n","  labels = classifier_df.label.values\n","\n","  test_set = build_data_set(texts, labels)\n","  test_text = texts\n","\n","  return classifier_df, test_set, test_text"],"metadata":{"id":"6e6aZy3xErsy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"executionInfo":{"elapsed":1771,"status":"ok","timestamp":1652391531979,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"},"user_tz":240},"id":"YGhkeLQlNNr8","outputId":"073e3c19-e05e-463b-bf5c-948875542b06"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data length: 1462\n","Test: 1462\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  a jumbled confession can only receive A jumble...      1\n","1                I love the rich Capulet's daughter.      1\n","2                , but we must have you to marry us.      1\n","3  I'll tell thee more in anon how and where we m...      1\n","4        , Holy Saint Francis, this is a changeable!      1"],"text/html":["\n","  <div id=\"df-854ee851-f8e4-4f9a-b6d6-91db3b5a1a37\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>a jumbled confession can only receive A jumble...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I love the rich Capulet's daughter.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>, but we must have you to marry us.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'll tell thee more in anon how and where we m...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>, Holy Saint Francis, this is a changeable!</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-854ee851-f8e4-4f9a-b6d6-91db3b5a1a37')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-854ee851-f8e4-4f9a-b6d6-91db3b5a1a37 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-854ee851-f8e4-4f9a-b6d6-91db3b5a1a37');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["classifier_df, test_set, test_text = get_test_set_text(\"Optimization/002/gen_predictions.csv\")\n","# classifier_df, test_set, test_text = get_test_set_text(\"T5-10-epochs-test1-outputs/gen_predictions.csv\")\n","# classifier_df, test_set, test_text = get_test_set_text(\"outputs_pseudo_parallel/003/gen_predictions.csv\")\n","\n","print(f\"Data length: {len(classifier_df)}\")\n","print(f\"Test: {len(test_text)}\")\n","classifier_df.head()"]},{"cell_type":"code","source":["pseudo_parallel_classifier_df, pseudo_parallel_test_set, pseudo_parallel_test_text = get_test_set_text(\"outputs_pseudo_parallel/003O/gen_predictions.csv\")\n","#pseudo_parallel_classifier_df, pseudo_parallel_test_set, pseudo_parallel_test_text = get_test_set_text(\"T5_2-5-epochs-test1-outputs-removed-shakespeare/001/gen_predictions.csv\")\n","#pseudo_parallel_classifier_df, pseudo_parallel_test_set, pseudo_parallel_test_text = get_test_set_text(\"T5-10-epochs-test1-outputs/gen_predictions.csv\")\n","print(f\"Data length: {len(pseudo_parallel_classifier_df)}\")\n","print(f\"Test: {len(pseudo_parallel_test_text)}\")\n","pseudo_parallel_classifier_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":242},"id":"ZSlMe716FqqT","executionInfo":{"status":"ok","timestamp":1652391819179,"user_tz":240,"elapsed":2096,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"}},"outputId":"56a4f73d-b4fe-4aa8-b421-e7c97ac54488"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data length: 1462\n","Test: 1462\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                text  label\n","0  , Shakespear, A jumbled confession can only re...      1\n","1                    I love rich Capulet's daughter.      1\n","2  Shakespear, we're bound to each other in every...      1\n","3  I'll tell you more later of when and where we ...      1\n","4      Holy Saint Francis, this is a drastic change!      1"],"text/html":["\n","  <div id=\"df-d6c37bf8-ee27-4706-ae86-24ab095f9926\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>, Shakespear, A jumbled confession can only re...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I love rich Capulet's daughter.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Shakespear, we're bound to each other in every...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I'll tell you more later of when and where we ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Holy Saint Francis, this is a drastic change!</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6c37bf8-ee27-4706-ae86-24ab095f9926')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d6c37bf8-ee27-4706-ae86-24ab095f9926 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d6c37bf8-ee27-4706-ae86-24ab095f9926');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"QCr006iTkqwM"},"source":["Here we choose the model we want to finetune from https://huggingface.co/transformers/pretrained_models.html. Because the task requires us to label sentences, we wil be using BertForSequenceClassification below. You may see a warning that states that `some weights of the model checkpoint at [model name] were not used when initializing. . .` This warning is expected and means that you should fine-tune your pre-trained model before using it on your downstream task. See [here](https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854) for more info."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPo640_ZlEPK"},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","def get_model(): \n","  model = BertForSequenceClassification.from_pretrained(\"classifier/001\")\n","\n","  # Tell pytorch to run this model on the GPU.\n","  model.cuda()\n","\n","  return model\n","\n","model = get_model()"]},{"cell_type":"markdown","metadata":{"id":"i3lLdoW_le3M"},"source":["# Hyperparameters #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1652391450160,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"},"user_tz":240},"id":"Dd2JdC6IletV","outputId":"ce037fe4-e76d-4ce0-c014-030848120163"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["batch_size = 128\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8\n","                )\n","epochs = 5"]},{"cell_type":"markdown","metadata":{"id":"Pd4fwn_el1ge"},"source":["# Fine-tune your model\n","Here we provide code for fine-tuning your model, monitoring the loss, and checking your validation accuracy. Rerun both of the below cells when you change your hyperparameters above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_Mzr-kd5RaY"},"outputs":[],"source":["import numpy as np\n","# function to get validation accuracy\n","def get_validation_performance(model, val_set, batch_size=100):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","\n","    num_batches = int(len(val_set)/batch_size) + 1\n","\n","    total_correct = 0\n","    results = []\n","\n","    for i in range(num_batches):\n","\n","      end_index = min(batch_size * (i+1), len(val_set))\n","\n","      batch = val_set[i*batch_size:end_index]\n","      \n","      if len(batch) == 0: continue\n","\n","      input_id_tensors = torch.stack([data[0] for data in batch])\n","      input_mask_tensors = torch.stack([data[1] for data in batch])\n","      label_tensors = torch.stack([data[2] for data in batch])\n","      \n","      # Move tensors to the GPU\n","      b_input_ids = input_id_tensors.to(device)\n","      b_input_mask = input_mask_tensors.to(device)\n","      b_labels = label_tensors.to(device)\n","        \n","      # Tell pytorch not to bother with constructing the compute graph during\n","      # the forward pass, since this is only needed for backprop (training).\n","      with torch.no_grad():        \n","\n","        # Forward pass, calculate logit predictions.\n","        outputs = model(b_input_ids, \n","                                token_type_ids=None, \n","                                attention_mask=b_input_mask,\n","                                labels=b_labels)\n","        loss = outputs.loss\n","        logits = outputs.logits\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the number of correctly labeled examples in batch\n","        pred_flat = np.argmax(logits, axis=1).flatten()\n","        labels_flat = label_ids.flatten()\n","        num_correct = np.sum(pred_flat == labels_flat)\n","        total_correct += num_correct\n","\n","        batch_results = pred_flat == labels_flat\n","        for row in batch_results:\n","          results.append(row)\n","          \n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_correct / len(val_set)\n","    return avg_val_accuracy, results\n","\n"]},{"cell_type":"markdown","metadata":{"id":"J9DpRJE5mHkO"},"source":["# Evaluate model on the test set\n"]},{"cell_type":"markdown","source":["## Parallel ##"],"metadata":{"id":"x7anhFk2F40B"}},{"cell_type":"code","source":["acc, results = get_validation_performance(model, test_set, batch_size)\n","print(acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBIMMX0sFx76","executionInfo":{"status":"ok","timestamp":1652391542339,"user_tz":240,"elapsed":6006,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"}},"outputId":"9e536be8-a23b-457e-92d0-74ba02e6318d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8331053351573188\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","labeledOutput = pd.read_csv(\"Optimization/002/gen_predictions.csv\")\n","labeledOutput['labels'] = [1 if label else 0 for label in results]\n","labeledOutput.drop('Unnamed: 0', axis=1, inplace=True)\n","labeledOutput.head()\n","\n","labeledOutput.to_csv(\"Optimization/002/labeled_en_predictions.csv\")"],"metadata":{"id":"htazvgmxsNof"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Pseudo Parallel ##"],"metadata":{"id":"nlrCDW9wF7Pe"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5321,"status":"ok","timestamp":1652391826923,"user":{"displayName":"Ala' Hashesh","userId":"02371999640038913792"},"user_tz":240},"id":"msvZ78ii3cZZ","outputId":"9143b1ba-5685-4f2a-e014-8e193095277c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.4466484268125855\n"]}],"source":["acc, _ = get_validation_performance(model, pseudo_parallel_test_set, batch_size)\n","print(acc)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Test Classifier.ipynb","provenance":[{"file_id":"1K-yEsHe9c4B6vBiL24t91BCovRN5ZP1a","timestamp":1647114885627},{"file_id":"1qWfGHzKDt2o0AuFEDJB3FAg_J6GE52nG","timestamp":1646435194169},{"file_id":"1Sl6tl-dL32oI5gEcofa-9Orjh9BWQkB7","timestamp":1646435132542},{"file_id":"12lyhUy6ZAN2BO8lCOUrdLG7cxkD2KrB4","timestamp":1646253268722},{"file_id":"1cTDpMUuJbxxaGEcNe11KQXLLweu8OA8r","timestamp":1646026402023},{"file_id":"1CRZfedkwWd5_NAIVp1vo6bz5xYkyTFgC","timestamp":1634149359597},{"file_id":"1K9H753cX0tD0lsoXvyHsDhrTtbnzq1bL","timestamp":1603002079306},{"file_id":"18v_7cFNT362Lzcmyg_PNKVnGQgVKc3i2","timestamp":1602459467767},{"file_id":"1bcAXWjkz8V8PK1FhnBrsb5YZAHKJiVFe","timestamp":1601580687210},{"file_id":"1wgo33YMqyTmwPXBCgDYvDD39Hgz516zV","timestamp":1599667757648},{"file_id":"1ZNQQshRjVp-0vLNi6ZGRtXX102EWHRq4","timestamp":1598302241860},{"file_id":"1XOa--UHuAQpBRcdqYbFcb8QuUTvywsSk","timestamp":1568522504552},{"file_id":"1LShMg_-e2SzrjDMxSgVbnYyTAgwcJov0","timestamp":1568420694683}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}